# Full corpus
WORKSPACE=/gpfsscratch/rech/wod/umz16dj
RUNPATH=$WORKSPACE/BERT_FR/code

DATASPACE=/gpfsscratch/rech/wod/umz16dj
OUTPUTPATH=$DATASPACE/Models/RoBERTa_large_64nodes
DATAPATH=$DATASPACE/Data/BERT-FR/50k_global_rank_1024

# Time limit in minutes (real number)
TIMELIMIT=1170

MAX_LEN=512
LAYERS=24
EMB_DIM=1024
HEADS=16
BATCH_SIZE=8
ACCUM_GRAD=64
EPOCH_SIZE=350000

optimizer="adam_inverse_sqrt,lr=0.0004,warmup_updates=30000,beta1=0.9,beta2=0.98,weight_decay=0.01,eps=0.000001"

EXPNAME="RoBERTa_large_embdim_"$EMB_DIM"_layers_"$LAYERS"_heads_"$HEADS"_batch_"$BATCH_SIZE"_accumgrad_"$ACCUM_GRAD"_epochsize_"$EPOCH_SIZE

#SBATCH --job-name=full_RoBERTa_large_v2    # nom du job
#SBATCH --partition=gpu_p1                     # demande d'allocation sur la partition GPU
#SBATCH --exclusive
#SBATCH --ntasks=256                 # nombre de tâche MPI
#SBATCH --ntasks-per-node=4         # nombre de tâche MPI par noeud
#SBATCH --gres=gpu:4                 # nombre de GPU à réserver par nœud
#SBATCH --cpus-per-task=10            # nombre de coeurs à réserver par tâche
#SBATCH --hint=nomultithread              
#SBATCH --time=19:59:30              # temps d'exécution maximum demande (HH:MM:SS) 
#SBATCH --output=full_RoBERTa_large_v2%j.out # nom du fichier de sortie
#SBATCH --error=full_RoBERTa_large_v2%j.stderr  # nom du fichier d'erreur (ici commun avec la sortie)

# Very slow convergence