# Full corpus
WORKSPACE=/gpfswork/rech/wod/umz16dj
RUNPATH=$WORKSPACE/BERT_FR/code

DATASPACE=/gpfsscratch/rech/wod/umz16dj
OUTPUTPATH=$DATASPACE/Models/Test_scaling/RoBERTa_base_node_2_gpu_4
DATAPATH=$DATASPACE/Data/BERT-FR/50k_global_rank_32

# Time limit in minutes (real number)
TIMELIMIT=15

MAX_LEN=512
LAYERS=12
EMB_DIM=768
HEADS=12
BATCH_SIZE=16
ACCUM_GRAD=16
EPOCH_SIZE=5000

optimizer="adam_inverse_sqrt,lr=0.0006,warmup_updates=24000,beta1=0.9,beta2=0.98,weight_decay=0.01,eps=0.000001"

EXPNAME="RoBERTa_base_embdim_"$EMB_DIM"_layers_"$LAYERS"_heads_"$HEADS"_batch_"$BATCH_SIZE"_accumgrad_"$ACCUM_GRAD"_epochsize_"$EPOCH_SIZE

#SBATCH --job-name=test_scaling    # nom du job
#SBATCH --partition=gpu_p1                     # demande d'allocation sur la partition GPU
#SBATCH --exclusive
#SBATCH --ntasks=4                 # nombre de tâche MPI
#SBATCH --ntasks-per-node=2         # nombre de tâche MPI par noeud
#SBATCH --gres=gpu:2                 # nombre de GPU à réserver par nœud
#SBATCH --cpus-per-task=10            # nombre de coeurs à réserver par tâche
#SBATCH --hint=nomultithread              
#SBATCH --time=00:06:00              # temps d'exécution maximum demande (HH:MM:SS) 
#SBATCH --output=test_scaling_node_2_gpu_4_%j.out # nom du fichier de sortie
#SBATCH --error=test_scaling_node_2_gpu_4_%j.stderr  # nom du fichier d'erreur (ici commun avec la sortie)
